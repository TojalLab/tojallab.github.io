[{"data":1,"prerenderedAt":249},["Reactive",2],{"content-query-fW8uSDGYBh":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":8,"description":9,"image":10,"authors":11,"category":14,"links":19,"body":26,"_type":244,"_id":245,"_source":246,"_file":247,"_extension":248},"/software/wsi2ml","software",false,"","WSI2ML - Digital Pathology Image annotator tool","The WSI2ML is Whole Slide Image annotation software focusing on generating high quality image datasets for Machine Learning.","/img/wsi2ml.jpg",[12,13],"Luan V. C. Martins","Israel Tojal da Silva",[15,16,17,18],"Imaging","Annotations","Dataset","Machine learning",[20,23],{"title":21,"url":22},"Software documentation","https://luanvcmartins.github.io/WSI2ML/",{"title":24,"url":25},"Github repository","https://github.com/luanvcmartins/WSI2ML",{"type":27,"children":28,"toc":232},"root",[29,38,44,49,54,61,68,73,99,106,111,124,129,135,140,146,159,178,184,195,201,206,212,217],{"type":30,"tag":31,"props":32,"children":34},"element","h1",{"id":33},"wsi2ml",[35],{"type":36,"value":37},"text","WSI2ML",{"type":30,"tag":39,"props":40,"children":41},"p",{},[42],{"type":36,"value":43},"WSI2ML is a straightforward tool for annotating Whole Slide Images (WSIs) for machine learning applications. WSIs are\nhigh-resolution digital images of entire tissue sections, often used in medical research and diagnosis. Annotating these\nimages can be a time-consuming and challenging task, but it is critical for training accurate machine learning models.",{"type":30,"tag":39,"props":45,"children":46},{},[47],{"type":36,"value":48},"The goal of WSI2ML is to streamline the annotation process, making it easy researchers and clinicians to label WSIs, and\nfor machine learning specialists to export and use the data for training new machine learning applications. The software\nintroduces a task-based approach to annotating data, which simplifies the process of training new annotators, tracking\ntheir progress and delegating new tasks. These annotations can then be used to train machine learning models to\naccurately diagnose diseases or predict patient outcomes.",{"type":30,"tag":39,"props":50,"children":51},{},[52],{"type":36,"value":53},"Developed as web-application, the software can be installed on a server and made accessible to users in your\norganization.",{"type":30,"tag":55,"props":56,"children":58},"h2",{"id":57},"ml-based-wsi-workflow",[59],{"type":36,"value":60},"ML-based WSI workflow",{"type":30,"tag":39,"props":62,"children":63},{},[64],{"type":30,"tag":65,"props":66,"children":67},"img",{"alt":65,"src":10},[],{"type":30,"tag":39,"props":69,"children":70},{},[71],{"type":36,"value":72},"Our goal with the software was to streamline the annotation, revision and ML-model interpretability when dealing with\nmulti-giga images. In particular, we need to fill the two following gaps we found lacking in currently available\nannotation software:",{"type":30,"tag":74,"props":75,"children":76},"ul",{},[77,89],{"type":30,"tag":78,"props":79,"children":80},"li",{},[81,87],{"type":30,"tag":82,"props":83,"children":84},"strong",{},[85],{"type":36,"value":86},"Simplified annotation process",{"type":36,"value":88},": the first step in generating a new image dataset is to have domain specialists\nannotate the image regions, this is often a daunting task if the software is too complicated use. To efficiently get\nnew domain-specialists on board, the tool must be as simple as possible to use to make the experience of training and\nadapting willing domain specialists easier.",{"type":30,"tag":78,"props":90,"children":91},{},[92,97],{"type":30,"tag":82,"props":93,"children":94},{},[95],{"type":36,"value":96},"Interpreting the model",{"type":36,"value":98},": the multigiga nature of those images makes it hard to get human feedback and understand\nhow the model behaves. In fact, domain specialists who are key in this aspect of research will often require full\naccess to the images in order to properly provide feedback on how the models work.",{"type":30,"tag":100,"props":101,"children":103},"h3",{"id":102},"annotate-image",[104],{"type":36,"value":105},"Annotate image",{"type":30,"tag":39,"props":107,"children":108},{},[109],{"type":36,"value":110},"The figure of the domain specialist is key in this research field, as they are needed in order to provide a wide range\nof input samples to train our deep learning models. The challenge is to recruit and train the specialist to be able to\nprovide the required domain-knowledge to train our models. It's of the upmost importance to make their experience of\nusing the software as smooth as possible, so they can focus on their task: provide carefully made annotations.",{"type":30,"tag":39,"props":112,"children":113},{},[114,116,122],{"type":36,"value":115},"The domain specialist experience using the software is simple: upon login, they can see their status page, which\nshows their progress and what images are remaining to be annotated. To start annotating, the user can simply press the\n",{"type":30,"tag":117,"props":118,"children":119},"em",{},[120],{"type":36,"value":121},"continue button",{"type":36,"value":123}," or choose a specific image that was delegated to them in the list.",{"type":30,"tag":39,"props":125,"children":126},{},[127],{"type":36,"value":128},"In particular, our task-based approach allows not only this simplified experience, but also allow more granular\ncontrol over who is expected to annotate what images.  Moreover, by using tasks, we add accountability into the mix: users\ncan track and quantify their progress, taking ownership of their work and participation on the success of the research\nendeavour.",{"type":30,"tag":100,"props":130,"children":132},{"id":131},"revising-annotations",[133],{"type":36,"value":134},"Revising annotations",{"type":30,"tag":39,"props":136,"children":137},{},[138],{"type":36,"value":139},"Once a task is completed, revision tasks can be made in the system so other pathologists can provide feedback on the\nannotations provided. This feedback is taken into account when exporting annotations, where the machine learning\nspecialist can choose to ignore annotations with low agree-ability.",{"type":30,"tag":100,"props":141,"children":143},{"id":142},"exporting-annotations",[144],{"type":36,"value":145},"Exporting annotations",{"type":30,"tag":39,"props":147,"children":148},{},[149,151,157],{"type":36,"value":150},"Annotations made through the software can be exported in any stage of the process as long as there are tasks\nmarked as completed. The annotations are exported in the ",{"type":30,"tag":152,"props":153,"children":154},"code-inline",{},[155],{"type":36,"value":156},"geojson",{"type":36,"value":158}," format, which provides the geometry and metadata\ninformation of the annotation for each annotated slide.",{"type":30,"tag":39,"props":160,"children":161},{},[162,164,169,171,176],{"type":36,"value":163},"ML specialists can customize the annotations exported, download the dynamically generated ",{"type":30,"tag":152,"props":165,"children":166},{},[167],{"type":36,"value":168},"zip",{"type":36,"value":170}," file, and use its\ndata to train their model as needed. This approach was chosen to allow any type of machine learning algorithm to be\nused. However, we also have provided a public python package to work with ",{"type":30,"tag":152,"props":172,"children":173},{},[174],{"type":36,"value":175},"image tiles",{"type":36,"value":177},".",{"type":30,"tag":100,"props":179,"children":181},{"id":180},"visualizing-and-interpreting-ml-model",[182],{"type":36,"value":183},"Visualizing and interpreting ML-model",{"type":30,"tag":39,"props":185,"children":186},{},[187,189,193],{"type":36,"value":188},"The publicly available annotation handling library also has utility functions to generate ",{"type":30,"tag":152,"props":190,"children":191},{},[192],{"type":36,"value":156},{"type":36,"value":194}," files that can\nbe uploaded into back the software to visualize the model as annotations. This is particularly useful when\nattempting to understand the model's inner workings and shortcomings.",{"type":30,"tag":100,"props":196,"children":198},{"id":197},"improving-annotations",[199],{"type":36,"value":200},"Improving annotations",{"type":30,"tag":39,"props":202,"children":203},{},[204],{"type":36,"value":205},"Lastly, once the ML model's results are available, domain specialists can continue to work on their annotations in\norder to improve model performance. This step was crucial in our image-related research, as it allowed us to\ndynamically understand the challenges, propose changes and guide our research process.",{"type":30,"tag":55,"props":207,"children":209},{"id":208},"install",[210],{"type":36,"value":211},"Install",{"type":30,"tag":39,"props":213,"children":214},{},[215],{"type":36,"value":216},"Follow the instructions available at the official documentation website:",{"type":30,"tag":74,"props":218,"children":219},{},[220],{"type":30,"tag":78,"props":221,"children":222},{},[223,231],{"type":30,"tag":224,"props":225,"children":228},"a",{"href":22,"rel":226},[227],"nofollow",[229],{"type":36,"value":230},"Official documentation",{"type":36,"value":177},{"title":7,"searchDepth":233,"depth":233,"links":234},2,[235,243],{"id":57,"depth":233,"text":60,"children":236},[237,239,240,241,242],{"id":102,"depth":238,"text":105},3,{"id":131,"depth":238,"text":134},{"id":142,"depth":238,"text":145},{"id":180,"depth":238,"text":183},{"id":197,"depth":238,"text":200},{"id":208,"depth":233,"text":211},"markdown","content:software:WSI2ML.md","content","software/WSI2ML.md","md",1696121330736]